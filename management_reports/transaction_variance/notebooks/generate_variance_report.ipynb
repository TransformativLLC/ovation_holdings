{
 "cells": [
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-05-15T19:21:07.362614Z",
     "start_time": "2025-05-15T19:21:06.453712Z"
    }
   },
   "cell_type": "code",
   "source": [
    "### Import Libraries\n",
    "# Azure Data Lake libraries\n",
    "import common.utils.azure_data_lake_interface as adl\n",
    "\n",
    "# data cleansing libraries\n",
    "from common.utils.data_cleansing import clean_illegal_chars_in_column\n",
    "\n",
    "# config libraries\n",
    "import common.config\n",
    "from common.utils.configuration_management import load_config\n",
    "\n",
    "# Data analysis libraries\n",
    "from pandas import DataFrame, Timedelta, to_datetime"
   ],
   "id": "initial_id",
   "outputs": [],
   "execution_count": 1
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-05-15T19:21:08.003415Z",
     "start_time": "2025-05-15T19:21:07.997449Z"
    }
   },
   "cell_type": "code",
   "source": [
    "def find_declining_margins(\n",
    "        df: DataFrame,\n",
    "        days: int,\n",
    "        tolerance: float = 0.0,\n",
    "        date_col: str = \"created_date\",\n",
    "        sku_col: str = \"sku\",\n",
    "        gpp_col: str = \"gross_profit_percent\",\n",
    "        trans_id_col: str = \"tranid\",\n",
    ") -> DataFrame:\n",
    "    \"\"\"\n",
    "    Identifies products with declining gross profit margins within a specified time window.\n",
    "\n",
    "    This function takes transaction data, computes the decline in gross profit percent for\n",
    "    each SKU over a specified period, and filters for transactions where this decline\n",
    "    exceeds a provided tolerance level. The final result is returned as a subset DataFrame\n",
    "    meeting these criteria.\n",
    "\n",
    "    Args:\n",
    "        df (DataFrame): Input DataFrame containing transactional data with gross profit\n",
    "            percent and dates of transactions.\n",
    "        days (int): Number of days to consider for the cutoff window. Only transactions\n",
    "            within this number of days from the latest transaction date are considered.\n",
    "        tolerance (float, optional): Minimum difference between the previous gross profit\n",
    "            percentage and the current one to qualify as a \"decline\". Default is 0.0.\n",
    "        date_col (str, optional): Name of the column in the DataFrame representing the\n",
    "            transaction dates. Default is \"created_date\".\n",
    "        sku_col (str, optional): Name of the column in the DataFrame identifying the\n",
    "            stock keeping unit (SKU). Default is \"sku\".\n",
    "        gpp_col (str, optional): Name of the column in the DataFrame representing the\n",
    "            gross profit percentage (GPP). Default is \"gross_profit_percent\".\n",
    "        trans_id_col (str, optional): Name of the column in the DataFrame representing the\n",
    "            transaction identifier. Default is \"tranid\".\n",
    "\n",
    "    Returns:\n",
    "        DataFrame: A subset of the input DataFrame containing rows where the gross profit\n",
    "        percentage for a product has declined by more than the specified tolerance within\n",
    "        the defined time window. The returned DataFrame includes columns for the current\n",
    "        and previous gross profit percentages, transaction dates, and transaction IDs.\n",
    "    \"\"\"\n",
    "\n",
    "    df = df.copy()\n",
    "\n",
    "    # 1. Parse and sort\n",
    "    df[date_col] = to_datetime(df[date_col], errors='raise')\n",
    "    df = df.sort_values([sku_col, date_col])\n",
    "\n",
    "    # 2. Compute the prior-value column\n",
    "    df['prev_gpp'] = df.groupby(sku_col)[gpp_col].shift(1)\n",
    "    df['prev_trans_date'] = df.groupby(sku_col)[date_col].shift(1)\n",
    "    if df[trans_id_col].dtype == 'string':\n",
    "        df['prev_trans_id'] = df.groupby(sku_col)[trans_id_col].shift(1).fillna('Not Specified').astype('string')\n",
    "    else:\n",
    "        df['prev_trans_id'] = df.groupby(sku_col)[trans_id_col].shift(1).fillna(0).astype(int)\n",
    "\n",
    "    # 3. Compute cutoff\n",
    "    cutoff = df['created_date'].max() - Timedelta(days=days)\n",
    "\n",
    "    # 4. Filter: within window AND declined\n",
    "    mask_window = df[date_col] >= cutoff\n",
    "    mask_declined = (df[\"prev_gpp\"] - df[gpp_col]) > tolerance\n",
    "    result = df[mask_window & mask_declined].copy()\n",
    "\n",
    "    # Calculate gpp_difference immediately after prev_gpp\n",
    "    result[\"gpp_difference\"] = round(result[\"gross_profit_percent\"] - result[\"prev_gpp\"], 2)\n",
    "\n",
    "    # Reorder columns to put gpp_difference after prev_gpp\n",
    "    cols = list(result.columns)\n",
    "    gpp_diff_idx = cols.index(\"gpp_difference\")\n",
    "    prev_gpp_idx = cols.index(\"prev_gpp\")\n",
    "    cols.insert(prev_gpp_idx + 1, cols.pop(gpp_diff_idx))\n",
    "    result = result[cols]\n",
    "\n",
    "    return result\n"
   ],
   "id": "d7a09923ea7c3bb1",
   "outputs": [],
   "execution_count": 2
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-05-15T19:29:22.905518Z",
     "start_time": "2025-05-15T19:29:22.897277Z"
    }
   },
   "cell_type": "code",
   "source": [
    "from openpyxl import load_workbook\n",
    "from openpyxl.worksheet.worksheet import Worksheet\n",
    "from openpyxl.styles import Font\n",
    "from openpyxl.utils import get_column_letter\n",
    "from typing import Optional, List\n",
    "\n",
    "\n",
    "class ExcelFormatterError(Exception):\n",
    "    \"\"\"Raised when formatting cannot be applied to the Excel file.\"\"\"\n",
    "    pass\n",
    "\n",
    "\n",
    "def format_worksheet(\n",
    "    file_path: str,\n",
    "    sheet_name: Optional[str] = None,\n",
    "    font_size: int = 14,\n",
    "    freeze_top_row: bool = True,\n",
    "    autofit_columns: bool = True,\n",
    "    max_col_width: int = 50,\n",
    "    padding: int = 2,\n",
    "    date_columns: Optional[List[str]] = None,\n",
    "    date_number_format: str = \"yyyy-mm-dd\",\n",
    "    number_columns: Optional[List[str]] = None,\n",
    "    number_format: str = \"0.00\",\n",
    "    currency_columns: Optional[List[str]] = None,\n",
    "    currency_number_format: str = \"$#,##0.00\",\n",
    "    enable_filter: bool = True,\n",
    "    verbose: bool = False\n",
    ") -> None:\n",
    "    \"\"\"\n",
    "    Apply formatting to an Excel worksheet, including:\n",
    "      1. Font size\n",
    "      2. Freeze top row\n",
    "      3. Auto-fit columns\n",
    "      4. Date, number, and currency formatting\n",
    "      5. Auto-filter\n",
    "    \"\"\"\n",
    "    wb = load_workbook(file_path)\n",
    "    ws: Worksheet = wb[sheet_name] if sheet_name else wb.active\n",
    "\n",
    "    max_col = ws.max_column\n",
    "    max_row = ws.max_row\n",
    "\n",
    "    # 1. Font sizing\n",
    "    for row in ws.iter_rows(min_row=1, max_row=max_row, min_col=1, max_col=max_col):\n",
    "        for cell in row:\n",
    "            if cell.value is not None:\n",
    "                cell.font = Font(size=font_size)\n",
    "\n",
    "    # 2. Freeze top row\n",
    "    if freeze_top_row:\n",
    "        ws.freeze_panes = \"A2\"\n",
    "\n",
    "    # 3. Auto-fit columns\n",
    "    if autofit_columns:\n",
    "        for col_idx in range(1, max_col + 1):\n",
    "            col_letter = get_column_letter(col_idx)\n",
    "            max_length = 0\n",
    "            for cell in ws[col_letter]:\n",
    "                if cell.value is not None:\n",
    "                    length = len(str(cell.value))\n",
    "                    if length > max_length:\n",
    "                        max_length = length\n",
    "            ws.column_dimensions[col_letter].width = min(max_length + padding, max_col_width)\n",
    "\n",
    "    # Map headers to columns (case-insensitive)\n",
    "    header_row = next(ws.iter_rows(min_row=1, max_row=1, values_only=False))\n",
    "    header_to_col = {\n",
    "        str(cell.value).strip().lower(): idx + 1\n",
    "        for idx, cell in enumerate(header_row)\n",
    "        if cell.value is not None\n",
    "    }\n",
    "    if verbose:\n",
    "        print(\"Header mapping:\", header_to_col)\n",
    "\n",
    "    def apply_number_format(headers: List[str], fmt: str, label: str):\n",
    "        for header in headers or []:\n",
    "            key = header.strip().lower()\n",
    "            col_idx = header_to_col.get(key)\n",
    "            if not col_idx:\n",
    "                if verbose:\n",
    "                    print(f\"Warning: {label} header '{header}' not found.\")\n",
    "                continue\n",
    "            for row_idx in range(2, max_row + 1):\n",
    "                cell = ws.cell(row=row_idx, column=col_idx)\n",
    "                if cell.value is not None:\n",
    "                    cell.number_format = fmt\n",
    "\n",
    "    apply_number_format(date_columns, date_number_format, \"Date\")\n",
    "    apply_number_format(number_columns, number_format, \"Number\")\n",
    "    apply_number_format(currency_columns, currency_number_format, \"Currency\")\n",
    "\n",
    "    # 7. Enable filtering\n",
    "    if enable_filter:\n",
    "        last_col_letter = get_column_letter(max_col)\n",
    "        ws.auto_filter.ref = f\"A1:{last_col_letter}{max_row}\"\n",
    "\n",
    "    wb.save(file_path)"
   ],
   "id": "2af7e121e8dbca6c",
   "outputs": [],
   "execution_count": 12
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-05-15T19:21:25.316812Z",
     "start_time": "2025-05-15T19:21:18.671778Z"
    }
   },
   "cell_type": "code",
   "source": [
    "# attach to the data lake\n",
    "config = load_config(common.config, \"datalake_config.json\")\n",
    "service_client = adl.get_azure_service_client(config[\"blob_url\"])\n",
    "file_system_client = adl.get_azure_file_system_client(service_client, \"consolidated\")\n",
    "\n",
    "# get data\n",
    "data_state = \"curated\"\n",
    "trans_type = \"Estimate\"\n",
    "filename = f\"transaction/{trans_type}ItemLineItems_{data_state}.parquet\"\n",
    "df = adl.get_parquet_file_from_data_lake(file_system_client, f\"{data_state}/netsuite\", filename)"
   ],
   "id": "e09fb18a85e06c6f",
   "outputs": [],
   "execution_count": 4
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-05-15T19:29:33.724050Z",
     "start_time": "2025-05-15T19:29:32.255088Z"
    }
   },
   "cell_type": "code",
   "source": [
    "lookback = 5\n",
    "margin_declines = find_declining_margins(df, days=lookback)\n",
    "print(f\"{margin_declines.shape[0]} declining margins found.\")\n",
    "df = clean_illegal_chars_in_column(df, \"description\")\n",
    "margin_declines.to_excel(f'../excel_outputs/{trans_type}ItemLineItems_margin_declines_in_past_{lookback}_days.xlsx', index=False)"
   ],
   "id": "f81801b4872733a8",
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "319 declining margins found.\n"
     ]
    }
   ],
   "execution_count": 13
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-05-15T19:29:34.765803Z",
     "start_time": "2025-05-15T19:29:34.096813Z"
    }
   },
   "cell_type": "code",
   "source": [
    "format_worksheet(\n",
    "    f'../excel_outputs/{trans_type}ItemLineItems_margin_declines_in_past_{lookback}_days.xlsx',\n",
    "    sheet_name=\"Sheet1\",\n",
    "    date_columns=[\"created_date\", \"prev_trans_date\"],\n",
    "    number_columns=[\"quantity\", \"labor_hours\", \"gross_profit_percent\", \"prev_gpp\", \"gpp_difference\"],\n",
    "    currency_columns=[\n",
    "        \"unit_cost\", \"highest_quoted_cost\", \"highest_recent_cost\", \"highest_cost\",\n",
    "        \"handling_cost\", \"unit_price\", \"total_cost\", \"total_amount\", \"gross_profit\"\n",
    "    ],\n",
    ")"
   ],
   "id": "8e7423bee2620c3c",
   "outputs": [],
   "execution_count": 14
  },
  {
   "metadata": {},
   "cell_type": "code",
   "source": "",
   "id": "9c554e6e486be353",
   "outputs": [],
   "execution_count": null
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
