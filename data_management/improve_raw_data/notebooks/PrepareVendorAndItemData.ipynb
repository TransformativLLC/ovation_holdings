{
 "cells": [
  {
   "cell_type": "code",
   "id": "initial_id",
   "metadata": {
    "collapsed": true,
    "ExecuteTime": {
     "end_time": "2025-05-04T22:58:09.428994Z",
     "start_time": "2025-05-04T22:58:08.749706Z"
    }
   },
   "source": [
    "import sys\n",
    "sys.path.append('/Users/markbills/Library/CloudStorage/OneDrive-Transformativ,LLC/Clients/Ovation Holdings/src')\n",
    "\n",
    "# Azure Data Lake libraries\n",
    "import azure_data_lake_interface as adl\n",
    "\n",
    "# Data analysis libraries\n",
    "import pandas as pd\n",
    "\n",
    "# Helper function libraries\n",
    "from helper_functions import load_config, convert_json_strings_to_python_types"
   ],
   "outputs": [],
   "execution_count": 1
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-05-04T22:58:10.149903Z",
     "start_time": "2025-05-04T22:58:10.146422Z"
    }
   },
   "cell_type": "code",
   "source": [
    "def clean_and_filter_vendor_data(vendors: pd.DataFrame) -> pd.DataFrame:\n",
    "    \"\"\"\n",
    "    Cleans and filters vendor data from a pandas DataFrame.\n",
    "\n",
    "    Args:\n",
    "        vendors (pd.DataFrame): DataFrame containing vendor information with columns:\n",
    "            links, balance, category, company_name, datecreated, etc.\n",
    "\n",
    "    Returns:\n",
    "        pd.DataFrame: Cleaned DataFrame with the following modifications:\n",
    "            - Removed 'links' column\n",
    "            - 'null' categories replaced with 'Not Assigned' \n",
    "            - 'datecreated' converted to datetime\n",
    "            - Numeric columns ('balance', 'unbilled_orders') converted to numbers\n",
    "    \"\"\"\n",
    "\n",
    "    # drop 'links' column\n",
    "    vendors.drop('links', axis=1, inplace=True)\n",
    "\n",
    "    # fill in values for category that are 'null'\n",
    "    vendors.loc[vendors['category'] == 'null', 'category'] = 'Not Assigned'\n",
    "\n",
    "    vendors = convert_json_strings_to_python_types(vendors)\n",
    "\n",
    "    return vendors"
   ],
   "id": "f8ec37ebbd05446e",
   "outputs": [],
   "execution_count": 2
  },
  {
   "metadata": {},
   "cell_type": "code",
   "source": [
    "# this code was used to find fuzzy duplicates in the manufacturer field, and the findings were used to create the manufacturer_name_map\n",
    "# used in the clean_and_resolve_manufacturers method\n",
    "\n",
    "# from thefuzz import fuzz\n",
    "# from collections import defaultdict\n",
    "# import pandas as pd\n",
    "#\n",
    "# # Set a threshold for similarity\n",
    "# similarity_threshold = 80\n",
    "#\n",
    "# # Create a dictionary where each key is a manufacturer name and\n",
    "# # the value is a list of tuples (other_name, similarity_ratio)\n",
    "# manufacturer_clusters = defaultdict(list)\n",
    "#\n",
    "# # Compare each manufacturer against the others\n",
    "# for i, name1 in enumerate(manufacturers):\n",
    "#     if name1 is None or pd.isna(name1):\n",
    "#         continue\n",
    "#     for name2 in manufacturers[i + 1:]:\n",
    "#         if name2 is None or pd.isna(name2):\n",
    "#             continue\n",
    "#         ratio = fuzz.ratio(name1, name2)\n",
    "#         if ratio >= similarity_threshold:\n",
    "#             manufacturer_clusters[name1].append((name2, ratio))\n",
    "#\n",
    "# clusters = []\n",
    "# for primary, similar_list in manufacturer_clusters.items():\n",
    "#     # Only include clusters where there is at least one similar name.\n",
    "#     if similar_list:\n",
    "#         # Cluster includes the primary manufacturer name first.\n",
    "#         cluster = [primary] + [name for name, score in similar_list]\n",
    "#         clusters.append(cluster)\n",
    "#\n",
    "# # Optionally, print out the clusters for verification.\n",
    "# print(\"Generated manufacturer clusters:\")\n",
    "# for main_name, similar in manufacturer_clusters.items():\n",
    "#     if similar:\n",
    "#         print(f\"\\nCluster for '{main_name}':\")\n",
    "#         for name, score in similar:\n",
    "#             print(f\"  - {name} (similarity: {score}%)\")"
   ],
   "id": "729055c82b2872f9",
   "outputs": [],
   "execution_count": null
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-05-04T22:58:14.314245Z",
     "start_time": "2025-05-04T22:58:14.309283Z"
    }
   },
   "cell_type": "code",
   "source": [
    "def clean_and_resolve_manufacturers(items: pd.DataFrame) -> pd.DataFrame:\n",
    "\n",
    "    # replace \"empty\" values with something more human-readable\n",
    "    items[\"manufacturer\"] = items[\"manufacturer\"].replace(\"null\", \"Not Specified\")\n",
    "    items[\"custom_manufacturer\"] = items[\"custom_manufacturer\"].replace(\"null\", \"Not Specified\")\n",
    "    items.loc[(items['vsi_mfr'] == \"null\") | (items['vsi_mfr'] == \"Unknown\") | (items['vsi_mfr'].isna()), 'vsi_mfr'] = \"Not Specified\"\n",
    "\n",
    "    # resolve multiple manufacturer columns\n",
    "    # -- put custom_manufacturer value in manufacturer if \"Not Specified\"\n",
    "    items.loc[items[\"manufacturer\"] == \"Not Specified\", \"manufacturer\"] = items[\"custom_manufacturer\"]\n",
    "\n",
    "    # -- put vsi_mfr value in manufacturer if \"Not Specified\" (which happens if custom_manufacturer was not specified)\n",
    "    items.loc[items[\"manufacturer\"] == \"Not Specified\", \"manufacturer\"] = items[\"vsi_mfr\"]\n",
    "\n",
    "    # Clean up manufacturer column\n",
    "    # -- remove special characters\n",
    "    items['manufacturer'] = items['manufacturer'].str.replace(r'[,.\\/-]', ' ', regex=True)\n",
    "\n",
    "    # -- remove leading/trailing spaces and replace multiple spaces with a single space\n",
    "    items['manufacturer'] = items['manufacturer'].str.strip()\n",
    "    items['manufacturer'] = items['manufacturer'].str.replace(r'\\s+', ' ', regex=True)\n",
    "\n",
    "    # -- capitalize the first letter of each word (removes all caps)\n",
    "    items['manufacturer'] = items['manufacturer'].str.title()\n",
    "\n",
    "    # remove all misspellings\n",
    "    mfg_name_map = load_config(\"config/manufacturer_name_map.json\", flush_cache=True)[\"manufacturer_map\"]\n",
    "    for correct_name, misspellings in mfg_name_map.items():\n",
    "        items.loc[items['manufacturer'].isin(misspellings), 'manufacturer'] = correct_name\n",
    "\n",
    "    return items"
   ],
   "id": "d30a0839c3a7f539",
   "outputs": [],
   "execution_count": 3
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-05-04T22:58:16.956916Z",
     "start_time": "2025-05-04T22:58:16.952439Z"
    }
   },
   "cell_type": "code",
   "source": [
    "def clean_and_filter_item_data(items: pd.DataFrame) -> pd.DataFrame:\n",
    "    \"\"\"\n",
    "    Cleans and filters item data from a pandas DataFrame.\n",
    "\n",
    "    Args:\n",
    "        items (pd.DataFrame): DataFrame containing item information with columns for\n",
    "            links, costs, manufacturers, descriptions, dates, quantities etc.\n",
    "\n",
    "    Returns:\n",
    "        pd.DataFrame: Cleaned DataFrame with the following modifications:\n",
    "            - Removed 'links' column\n",
    "            - Resolved manufacturer/custom_manufacturer columns\n",
    "            - Replaced 'null' values with 'Not Specified' in text columns\n",
    "            - Converted date columns to datetime\n",
    "            - Converted numeric columns to numbers\n",
    "    \"\"\"\n",
    "\n",
    "    items = convert_json_strings_to_python_types(items)\n",
    "\n",
    "    # drop 'links' column\n",
    "    items.drop('links', axis=1, inplace=True)\n",
    "\n",
    "    # fill in values for columns of interest that contain 'null'\n",
    "    nulls = [\n",
    "        'description', 'display_name', 'level_1_category', 'level_2_category', 'level_3_category',\n",
    "        'parent_item', 'preferred_vendor', 'valve_spec_size'\n",
    "    ]\n",
    "    for col in nulls:\n",
    "        items[col] = items[col].apply(lambda x: str(x) if not pd.isna(x) else 'Not Specified')\n",
    "        items.loc[items[col] == 'null', col] = 'Not Specified'\n",
    "\n",
    "    # fill in \"empty\" vsi_item_category values\n",
    "    items.loc[(items['vsi_item_category'] == \"null\") | (items['vsi_item_category'] == \"Unknown\") | (items['vsi_item_category'].isna()), 'vsi_item_category'] = \"Not Specified\"\n",
    "\n",
    "    # move any valid manufacturer into the manufacturer field from custom or vsi fields\n",
    "    items = clean_and_resolve_manufacturers(items)\n",
    "\n",
    "    # remove items with item_names that start with \"Inactivated\"\n",
    "    items = items[~items[\"item_name\"].str.startswith(\"Inactivated\")]\n",
    "\n",
    "    # remove items with item names that contain the word \"custom\"\n",
    "    items = items[~items[\"item_name\"].str.contains(r'\\bcustom\\b', case=False, regex=True)]\n",
    "\n",
    "    return items"
   ],
   "id": "a99cbc25e999e02c",
   "outputs": [],
   "execution_count": 4
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-05-04T22:58:21.210671Z",
     "start_time": "2025-05-04T22:58:21.205137Z"
    }
   },
   "cell_type": "code",
   "source": [
    "def add_new_item_levels(items: pd.DataFrame, new_item_info_path: str, create_new_columns: bool = True) -> pd.DataFrame:\n",
    "    \"\"\"Adds new item level categories from an Excel file to the items DataFrame.\n",
    "\n",
    "    Args:\n",
    "        items (pd.DataFrame): DataFrame containing item information with existing level categories.\n",
    "        new_item_info_path (str): Path to Excel file containing new level information.\n",
    "        create_new_columns (bool, optional): Whether to create new level columns 4-6. Defaults to True.\n",
    "\n",
    "    Returns:\n",
    "        pd.DataFrame: Items DataFrame with updated level categories.\n",
    "    \"\"\"\n",
    "\n",
    "    if create_new_columns:\n",
    "        # add new level columns to items\n",
    "        for i in [4, 5, 6]:\n",
    "            items[f\"level_{i}_category\"] = 'Not Specified'\n",
    "\n",
    "        # rearrange the columns so that the levels are contiguous\n",
    "        columns_before = items.columns[0:items.columns.get_loc(\"level_3_category\") + 1].tolist()\n",
    "        level_columns = [f\"level_{i}_category\" for i in [4, 5, 6]]\n",
    "        remaining_columns = [col for col in items.columns if col not in columns_before + level_columns]\n",
    "        items = items[columns_before + level_columns + remaining_columns]\n",
    "\n",
    "    # get new level information in Excel\n",
    "    level_info = pd.read_excel(new_item_info_path)\n",
    "\n",
    "    # convert all level values to string (Excel treats some as numbers)\n",
    "    for i in range(1, 7):\n",
    "        level_info[f'Level {i}'] = level_info[f'Level {i}'].astype(str)\n",
    "\n",
    "    # Update level categories for matching items\n",
    "    for i in range(1, 7):\n",
    "        items.loc[items['item_name'].isin(level_info['Name']), f'level_{i}_category'] = \\\n",
    "            items[items['item_name'].isin(level_info['Name'])]['item_name'].map(\n",
    "                dict(zip(level_info['Name'], level_info[f'Level {i}']))\n",
    "            )\n",
    "\n",
    "    # replace nan strings with \"Not Specified\"\n",
    "    for i in range(1, 7):\n",
    "        items[f'level_{i}_category'] = items[f'level_{i}_category'].replace(\"nan\", \"Not Specified\")\n",
    "\n",
    "    # replace old category with the updated one\n",
    "    items[\"level_1_category\"] = items[\"level_1_category\"].replace(\"Valve\", \"Valves\")\n",
    "\n",
    "    return items"
   ],
   "id": "280f6c9b0fb3fe72",
   "outputs": [],
   "execution_count": 5
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-05-04T22:58:24.853913Z",
     "start_time": "2025-05-04T22:58:24.850203Z"
    }
   },
   "cell_type": "code",
   "source": [
    "# attach to the data lake\n",
    "config = load_config(\"config/datalake_config.json\", flush_cache=True)\n",
    "service_client = adl.get_azure_service_client(config[\"blob_url\"])\n",
    "\n",
    "container_name = \"consolidated\"\n",
    "file_system_client = adl.get_azure_file_system_client(service_client, container_name)"
   ],
   "id": "280fed998d959481",
   "outputs": [],
   "execution_count": 6
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-05-04T22:58:30.807838Z",
     "start_time": "2025-05-04T22:58:27.473752Z"
    }
   },
   "cell_type": "code",
   "source": [
    "# get vendor and item data\n",
    "source_folder = \"raw/netsuite\"\n",
    "vendors = adl.get_parquet_file_from_data_lake(file_system_client, source_folder, \"vendor_raw.parquet\")\n",
    "items = adl.get_parquet_file_from_data_lake(file_system_client, source_folder, \"item_raw.parquet\")"
   ],
   "id": "cdd5e9a60b7a777b",
   "outputs": [],
   "execution_count": 7
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-05-04T22:58:37.071660Z",
     "start_time": "2025-05-04T22:58:31.566924Z"
    }
   },
   "cell_type": "code",
   "source": [
    "vendors = clean_and_filter_vendor_data(vendors)\n",
    "items = clean_and_filter_item_data(items)\n",
    "\n",
    "# save in the data lake\n",
    "adl.save_df_as_parquet_in_data_lake(vendors, file_system_client, \"cleaned/netsuite\", \"vendor_cleaned.parquet\")\n",
    "adl.save_df_as_parquet_in_data_lake(items, file_system_client, \"cleaned/netsuite\", \"item_cleaned.parquet\")"
   ],
   "id": "dd89f5a536736ae2",
   "outputs": [],
   "execution_count": 8
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-05-04T22:58:47.410061Z",
     "start_time": "2025-05-04T22:58:40.862483Z"
    }
   },
   "cell_type": "code",
   "source": [
    "# add new item category levels and save as enhanced\n",
    "items = add_new_item_levels(items,\n",
    "                            \"../../../../../../../../Dropbox/Transformativ/ClientSystems/ResearchAndDevelopment/AzureDataLakeAccess/client_data/NewItemLevels.xlsx\")\n",
    "adl.save_df_as_parquet_in_data_lake(items, file_system_client, \"enhanced/netsuite\", \"item_enhanced.parquet\")"
   ],
   "id": "9a7b9cefad23d467",
   "outputs": [],
   "execution_count": 9
  },
  {
   "metadata": {},
   "cell_type": "code",
   "source": "",
   "id": "73c03dae0532cbba",
   "outputs": [],
   "execution_count": null
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
