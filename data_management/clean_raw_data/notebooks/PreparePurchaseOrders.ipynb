{
 "cells": [
  {
   "cell_type": "code",
   "id": "initial_id",
   "metadata": {
    "collapsed": true,
    "ExecuteTime": {
     "end_time": "2025-05-05T00:54:07.537359Z",
     "start_time": "2025-05-05T00:54:06.853998Z"
    }
   },
   "source": [
    "import sys\n",
    "sys.path.append('/Users/markbills/Library/CloudStorage/OneDrive-Transformativ,LLC/Clients/Ovation Holdings/src')\n",
    "\n",
    "# Standard libraries\n",
    "import datetime\n",
    "from typing import Tuple\n",
    "\n",
    "# Azure Data Lake libraries\n",
    "import azure_data_lake_interface as adl\n",
    "\n",
    "# Data analysis libraries\n",
    "import pandas as pd\n",
    "\n",
    "# Helper function libraries\n",
    "import helper_functions as hf"
   ],
   "outputs": [],
   "execution_count": 1
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-05-05T00:54:10.674324Z",
     "start_time": "2025-05-05T00:54:10.668922Z"
    }
   },
   "cell_type": "code",
   "source": [
    "def clean_filter_augment_purchase_orders(transactions: pd.DataFrame,\n",
    "                                          line_items: pd.DataFrame,\n",
    "                                          items: pd.DataFrame) -> Tuple[pd.DataFrame, pd.DataFrame]:\n",
    "    \"\"\"\n",
    "    Cleans, filters, and augments purchase orders by processing transactions and line items data.\n",
    "    This function applies transformations such as date range filtering, removing irrelevant data, dropping\n",
    "    non-essential columns, converting data types, and incorporating additional data from vendor and item\n",
    "    sources. The resulting datasets are refined to better reflect purchase order data.\n",
    "\n",
    "    Args:\n",
    "        transactions (pd.DataFrame): DataFrame containing transaction records.\n",
    "        line_items (pd.DataFrame): DataFrame containing line item records associated with transactions.\n",
    "        vendors (pd.DataFrame): DataFrame containing vendor information.\n",
    "        items (pd.DataFrame): DataFrame of item records, including product or service details.\n",
    "\n",
    "    Returns:\n",
    "        Tuple[pd.DataFrame, pd.DataFrame]: A tuple where the first element is the cleaned and transformed\n",
    "            transactions DataFrame, and the second element is the cleaned and augmented line items DataFrame.\n",
    "\n",
    "    \"\"\"\n",
    "\n",
    "    # most columns in the transactions don't make sense for purchase orders, so drop them\n",
    "    drop_columns = [\n",
    "        'links', 'actual_ship_date', 'ai_order_type', 'amount_paid', 'amount_unpaid', 'billing_address',\n",
    "        'close_date', 'commission_only', 'company_email', 'created_by', 'custom_form', 'date_started',\n",
    "        'days_open', 'deliver_by_date', 'due_date', 'employee', 'end_date', 'entered_by', 'entity_status',\n",
    "        'estimated_gross_profit', 'estimated_gross_profit_percent', 'expected_close_date', 'finance_charge',\n",
    "        'freshdesk_ticket_number', 'inbound_source', 'job_type', 'last_modified_by', 'lastmodifieddate',\n",
    "        'lead_source', 'mainline', 'memo', 'nexus', 'posting_period', 'prepared_for_contact',\n",
    "        'prepared_for_contact_email', 'promised_date', 'reversal', 'ship_date', 'shipping_address', 'start_date',\n",
    "        'type', 'voided', 'nx_customer_id', 'vsi_service_type'\n",
    "    ]\n",
    "    transactions = transactions.drop(columns=drop_columns)\n",
    "\n",
    "    # similarly, most line item columns don't make sense for purchase orders, so drop them\n",
    "    drop_columns = [\n",
    "        'links', 'amount', 'assembly_component', 'cost_estimate_type', 'created_from', 'custcol_ava_taxamount',\n",
    "        'custcol_sa_quote_po_rate', 'est_extended_cost', 'est_gross_profit', 'est_gross_profit_percent',\n",
    "        'handling_cost', 'item_base_price', 'labor_hours', 'line_number', 'mainline',\n",
    "        'nx_customer_id', 'quote_po_rate', 'special_order', 'tax_line', 'transaction_table_id', 'valve_spec_size',\n",
    "        'vendor_commission_percent'\n",
    "    ]\n",
    "    line_items = line_items.drop(columns=drop_columns)\n",
    "\n",
    "    transactions = hf.convert_json_strings_to_python_types(transactions)\n",
    "    line_items = hf.convert_json_strings_to_python_types(line_items)\n",
    "\n",
    "    # add created date to line items\n",
    "    line_items = line_items.merge(transactions[[\"tranid\", \"created_date\"]], on=\"tranid\", how=\"left\")\n",
    "\n",
    "    # drop item types that are not related to products/services\n",
    "    drop_list = [\"Description\", \"Markup\", \"Other Charge\", \"Payment\", \"Discount\"]\n",
    "    line_items = line_items[~line_items[\"item_type\"].isin(drop_list)]\n",
    "\n",
    "    # Replace null values with replacement_value\n",
    "    transactions[\"location\"] = transactions[\"location\"].replace(\"null\", \"Not Specified\")\n",
    "    line_items[\"location\"] = line_items[\"location\"].replace(\"null\", \"Not Specified\")\n",
    "\n",
    "    # replace values in line items with values from item master (levels and manufacturer)\n",
    "    line_items = hf.add_category_levels_and_vsi_info(line_items, items)\n",
    "\n",
    "    # calculate total amount for each line item\n",
    "    line_items[\"total_amount\"] = line_items[\"quantity\"] * line_items[\"unit_price\"]\n",
    "\n",
    "    return transactions, line_items"
   ],
   "id": "7d2dca93a909e3b6",
   "outputs": [],
   "execution_count": 2
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-05-05T00:54:15.614198Z",
     "start_time": "2025-05-05T00:54:15.609832Z"
    }
   },
   "cell_type": "code",
   "source": [
    "# attach to the data lake\n",
    "config = hf.load_config(\"config/datalake_config.json\", flush_cache=True)\n",
    "service_client = adl.get_azure_service_client(config[\"blob_url\"])\n",
    "file_system_client = adl.get_azure_file_system_client(service_client, \"consolidated\")"
   ],
   "id": "280fed998d959481",
   "outputs": [],
   "execution_count": 3
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-05-05T00:54:24.020350Z",
     "start_time": "2025-05-05T00:54:16.676450Z"
    }
   },
   "cell_type": "code",
   "source": [
    "# get transaction-level and line item data\n",
    "trans_type = \"PurchOrd\"\n",
    "transactions, line_items = adl.get_transactions_and_line_items(file_system_client, trans_type)"
   ],
   "id": "61d69fad3abbbede",
   "outputs": [],
   "execution_count": 4
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-05-05T00:54:29.837876Z",
     "start_time": "2025-05-05T00:54:25.259998Z"
    }
   },
   "cell_type": "code",
   "source": [
    "# get vendor data\n",
    "vendors = adl.get_parquet_file_from_data_lake(file_system_client, \"cleaned/netsuite\", \"vendor_cleaned.parquet\")\n",
    "items = adl.get_parquet_file_from_data_lake(file_system_client, \"enhanced/netsuite\", \"item_enhanced.parquet\")"
   ],
   "id": "7c77b80516755434",
   "outputs": [],
   "execution_count": 5
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-05-05T00:54:37.604436Z",
     "start_time": "2025-05-05T00:54:31.497176Z"
    }
   },
   "cell_type": "code",
   "source": [
    "start_date = \"2022-01-01\"\n",
    "end_date = datetime.date.today().strftime(\"%Y-%m-%d\")\n",
    "\n",
    "transactions, line_items = clean_filter_augment_purchase_orders(transactions, line_items, items)\n",
    "\n",
    "# save in data lake\n",
    "adl.save_df_as_parquet_in_data_lake(transactions, file_system_client, \"cleaned/netsuite\", f\"transaction/{trans_type}_cleaned.parquet\")\n",
    "adl.save_df_as_parquet_in_data_lake(line_items, file_system_client, \"cleaned/netsuite\", f\"transaction/{trans_type}ItemLineItems_cleaned.parquet\")"
   ],
   "id": "5a8e844a3b0f24b4",
   "outputs": [],
   "execution_count": 6
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-05-05T00:54:49.096067Z",
     "start_time": "2025-05-05T00:54:47.208625Z"
    }
   },
   "cell_type": "code",
   "source": [
    "# add vendor information to line_items after changing col name\n",
    "vendors.rename(columns={\"id\": \"vendor_id\"}, inplace=True)\n",
    "augmented_line_items = line_items.merge(vendors[[\"vendor_id\", \"company_name\", \"category\"]], on=\"vendor_id\", how=\"left\")\n",
    "\n",
    "# save in the data lake\n",
    "adl.save_df_as_parquet_in_data_lake(augmented_line_items, file_system_client, \"enhanced/netsuite\", f\"transaction/{trans_type}ItemLineItems_enhanced.parquet\")"
   ],
   "id": "c9a99fe6a52f160f",
   "outputs": [],
   "execution_count": 7
  },
  {
   "metadata": {},
   "cell_type": "code",
   "outputs": [],
   "execution_count": null,
   "source": "",
   "id": "2a1e76e49a80822d"
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
